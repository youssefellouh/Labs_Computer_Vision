{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 : Dans quels cas la transformation entre deux images est-elle une homographie?\n",
    "\n",
    "Cette question ne nécessite pas de code, mais voici la réponse :\n",
    "\n",
    "1. Lorsque les images sont des projections planes d'une même scène 3D.\n",
    "2. Quand on change de point de vue sur un plan dans la scène.\n",
    "3. Pour des rotations pures de la caméra (sans translation).\n",
    "4. Lors de changements de focale de la caméra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 : À partir du code fourni, essayez d'estimer l'homographie permettant de transformer l'image de la mosaïque Pompei.jpg en vue verticale (en supposant le cadre carré, voir Figure 1).\n",
    "\n",
    "Le code pour cette partie est déjà fourni dans le script initial. Voici les parties importantes :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version d'OpenCV:  4.10.0\n",
      "Dimension de l'image : 333 lignes x 500 colonnes x 3 couleurs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/youssef/Desktop/Labs_Computer_Vision/new-venv/lib/python3.12/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "print(\"Version d'OpenCV: \", cv2.__version__)\n",
    "\n",
    "# Charger l'image\n",
    "PATH_IMG = './Images_Homographie/'\n",
    "img = cv2.imread(PATH_IMG + \"Pompei.jpg\")\n",
    "\n",
    "if img is None:\n",
    "    print(\"Erreur : impossible de charger l'image.\")\n",
    "    exit(1)\n",
    "\n",
    "(h, w, c) = img.shape\n",
    "print(\"Dimension de l'image :\", h, \"lignes x\", w, \"colonnes x\", c, \"couleurs\")\n",
    "\n",
    "# Variables globales pour le clic\n",
    "points_selected = 0\n",
    "X_init = []\n",
    "clone = img.copy()\n",
    "\n",
    "# Fonction de sélection des points\n",
    "def select_points(event, x, y, flags, param):\n",
    "    global points_selected, X_init, img, clone\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:  # Clic gauche pour sélectionner un point\n",
    "        points_selected += 1\n",
    "        cv2.circle(img, (x, y), 8, (0, 255, 255), -1)  # Dessiner un cercle\n",
    "        cv2.line(img, (x - 8, y), (x + 8, y), (0, 255, 0), 1)  # Ligne horizontale\n",
    "        cv2.line(img, (x, y - 8), (x, y + 8), (0, 255, 0), 1)  # Ligne verticale\n",
    "        X_init.append([x, y])  # Ajouter le point sélectionné\n",
    "    elif event == cv2.EVENT_RBUTTONDOWN:  # Clic droit pour réinitialiser\n",
    "        points_selected = 0\n",
    "        X_init = []\n",
    "        img = clone.copy()\n",
    "\n",
    "# Initialiser la fenêtre et le callback\n",
    "cv2.namedWindow(\"Image initiale\")\n",
    "cv2.setMouseCallback(\"Image initiale\", select_points)\n",
    "\n",
    "# Afficher l'image et sélectionner les points\n",
    "while True:\n",
    "    cv2.imshow(\"Image initiale\", img)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if (key == ord(\"q\")) and (points_selected >= 4):  # Touche 'q' pour valider\n",
    "        break\n",
    "\n",
    "# Conversion des points initiaux en array numpy\n",
    "X_init = np.asarray(X_init, dtype=np.float32)\n",
    "print(\"Points initiaux (X_init) :\", X_init)\n",
    "\n",
    "# Demander les coordonnées des points correspondants\n",
    "X_final = np.zeros((points_selected, 2), np.float32)\n",
    "print(\"\\nEntrez les coordonnées cibles des points correspondants (par exemple pour un carré parfait) :\")\n",
    "for i in range(points_selected):\n",
    "    while True:\n",
    "        try:\n",
    "            coords = input(f\"Correspondant pour {X_init[i]} (format: x y) : \")\n",
    "            x, y = map(float, coords.split())\n",
    "            X_final[i] = [x, y]\n",
    "            break\n",
    "        except ValueError:\n",
    "            print(\"Entrée invalide. Veuillez entrer deux nombres séparés par un espace.\")\n",
    "\n",
    "print(\"Points finaux (X_final) :\", X_final)\n",
    "\n",
    "# Calcul de l'homographie\n",
    "H, status = cv2.findHomography(X_init, X_final, cv2.RANSAC)\n",
    "if H is None:\n",
    "    print(\"Erreur : le calcul de l'homographie a échoué.\")\n",
    "    exit(1)\n",
    "\n",
    "# Application de l'homographie\n",
    "img_warp = cv2.warpPerspective(clone, H, (w, h))\n",
    "cv2.imshow(\"Image rectifiée\", img_warp)\n",
    "\n",
    "# Sauvegarde ou sortie\n",
    "while True:\n",
    "    key = cv2.waitKey(0)\n",
    "    if key == ord(\"q\"):  # Quitter sans sauvegarder\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n",
    "    elif key == ord(\"s\"):  # Sauvegarder l'image\n",
    "        cv2.imwrite(\"img_rectified.png\", img_warp)\n",
    "        print(\"Image sauvegardée sous 'img_rectified.png'.\")\n",
    "        cv2.destroyAllWindows()\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combien de points au minimum devez-vous sélectionner ?\n",
    "\n",
    "Pour estimer une homographie, **au moins 4 points correspondants** sont nécessaires. \n",
    "\n",
    "#### **Explication :**\n",
    "1. **Homographie :**  \n",
    "   Une homographie \\( H \\) est une transformation projective définie par une matrice \\( 3 \\times 3 \\) :\n",
    "   $$\n",
    "   H = \\begin{pmatrix} \n",
    "   h_{11} & h_{12} & h_{13} \\\\\n",
    "   h_{21} & h_{22} & h_{23} \\\\\n",
    "   h_{31} & h_{32} & 1\n",
    "   \\end{pmatrix} \n",
    "   $$\n",
    "   Cette matrice a **8 degrés de liberté** (9 paramètres, mais l'échelle est arbitraire, donc \\( h_{33} = 1 \\)).\n",
    "\n",
    "2. **Équations par point :**  \n",
    "   Chaque point de correspondance \\((x, y) \\leftrightarrow (x', y')\\) génère deux équations linéaires :\n",
    "   $$\n",
    "   x' = \\frac{h_{11}x + h_{12}y + h_{13}}{h_{31}x + h_{32}y + 1}, \\quad\n",
    "   y' = \\frac{h_{21}x + h_{22}y + h_{23}}{h_{31}x + h_{32}y + 1}.\n",
    "   $$\n",
    "   Ces équations peuvent être réécrites sous forme matricielle.\n",
    "\n",
    "3. **Nombre d'équations nécessaires :**  \n",
    "   Chaque point de correspondance fournit 2 équations. Ainsi, pour résoudre un système d'équations avec 8 inconnues (les coefficients de \\( H \\)), **4 points sont nécessaires** :\n",
    "   $$\n",
    "   4 \\text{ points } \\times 2 \\text{ équations par point } = 8 \\text{ équations.}\n",
    "   $$\n",
    "\n",
    "- danc Le **minimum requis** est **4 points correspondants** pour calculer l'homographie.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3 : Pour estimer l'homographie, créez la matrice 2n×9 A comme indiqué en cours à partir de vos n correspondances, puis résolvez le système Ah=0 en utilisant la décomposition en valeurs singulières de numpy.\n",
    "\n",
    "Voici le code pour estimer l'homographie :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/youssef/Desktop/Labs_Computer_Vision/new-venv/lib/python3.12/site-packages/cv2/qt/plugins\"\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Fonction pour estimer l'homographie\n",
    "def estimate_homography(points1, points2):\n",
    "    # Créer la matrice A de dimension 2n x 9\n",
    "    A = []\n",
    "    for i in range(len(points1)):\n",
    "        x1, y1 = points1[i]\n",
    "        x2, y2 = points2[i]\n",
    "        A.append([-x1, -y1, -1, 0, 0, 0, x2 * x1, x2 * y1, x2])\n",
    "        A.append([0, 0, 0, -x1, -y1, -1, y2 * x1, y2 * y1, y2])\n",
    "    \n",
    "    A = np.array(A)\n",
    "\n",
    "    # Appliquer la décomposition en valeurs singulières\n",
    "    U, S, V = np.linalg.svd(A)\n",
    "    \n",
    "    # Extraire le dernier vecteur de V (associé à la plus petite valeur singulière)\n",
    "    h = V[-1]\n",
    "    \n",
    "    # Reshape h pour obtenir la matrice H 3x3\n",
    "    H = h.reshape(3, 3)\n",
    "    \n",
    "    return H\n",
    "\n",
    "# Fonction pour appliquer l'homographie sur l'image\n",
    "def apply_homography(img1, img2, H):\n",
    "    # Appliquer la transformation sur l'image\n",
    "    height, width = img1.shape[:2]\n",
    "    img2_warped = cv2.warpPerspective(img2, H, (width, height))\n",
    "    return img2_warped\n",
    "\n",
    "# Exemple d'utilisation avec des points correspondants\n",
    "points1 = [(100, 150), (200, 250), (300, 350), (400, 450)]  # Points dans la première image\n",
    "points2 = [(110, 160), (210, 260), (310, 360), (410, 460)]  # Points dans la deuxième image\n",
    "\n",
    "# Estimer l'homographie\n",
    "H = estimate_homography(points1, points2)\n",
    "\n",
    "# Charger les images\n",
    "img1 = cv2.imread('./Images_Homographie/paris_a.jpg')  # Remplacer par votre image\n",
    "img2 = cv2.imread('./Images_Homographie/paris_b.jpg')  # Remplacer par votre image\n",
    "\n",
    "# Appliquer l'homographie pour transformer img2 dans le référentiel de img1\n",
    "img2_warped = apply_homography(img1, img2, H)\n",
    "\n",
    "# Afficher l'image résultante\n",
    "cv2.imshow(\"Warped Image\", img2_warped)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Afficher la matrice d'homographie\n",
    "print(\"Matrice d'homographie H :\")\n",
    "print(H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L’intérêt du traitement de l’homographie\n",
    "\n",
    "Le traitement de l’homographie a plusieurs intérêts clés, principalement dans le domaine de la vision par ordinateur et de la géométrie projective. Voici quelques-uns des principaux objectifs :\n",
    "\n",
    "1. **Alignement d'images prises sous des angles différents** :  \n",
    "   L'homographie permet d’ajuster ou de \"transformer\" une image pour qu’elle corresponde à une autre, même si elles ont été prises sous des perspectives différentes. Cela est essentiel pour des applications telles que la création de panoramas, où plusieurs images doivent être fusionnées de manière transparente pour former une seule vue d'ensemble.\n",
    "\n",
    "2. **Correction de la perspective** :  \n",
    "   L'homographie permet de corriger les déformations dues à la perspective dans les images. Par exemple, dans les photographies d’un objet pris sous différents angles, l’homographie permet de \"redresser\" l’image en fonction d’un plan de référence.\n",
    "\n",
    "3. **Modélisation de scènes 3D et réalité augmentée** :  \n",
    "   Dans des systèmes de réalité augmentée ou de modélisation 3D, l’homographie est utilisée pour estimer la transformation entre les vues d’une scène ou d’un objet. Cela aide à superposer des objets virtuels sur des vues réelles, ajustant correctement la position et la perspective.\n",
    "\n",
    "4. **Suivi d'objets dans les vidéos** :  \n",
    "   L’homographie est utilisée pour le suivi d'objets dans des séquences vidéo, en ajustant les coordonnées des objets dans différentes images pour suivre leurs déplacements dans une scène 2D.\n",
    "\n",
    "# Indices de confiance pour évaluer la fiabilité du résultat\n",
    "\n",
    "Une fois l’homographie estimée, il est important de mesurer la qualité de cette estimation. Voici quelques indices de confiance utilisés pour évaluer la fiabilité de l’homographie :\n",
    "\n",
    "1. **Erreur de projection** :  \n",
    "   L'un des indices les plus simples consiste à mesurer l'erreur de projection des points transformés par l'homographie. Cela consiste à appliquer l’homographie estimée aux points de l'image d’origine et comparer les points projetés aux points correspondants dans l’image cible. Une petite erreur de projection (ou résidu) indique que l’homographie est fiable.\n",
    "\n",
    "   L'erreur de projection est calculée par :\n",
    "   $$ [\n",
    "   \\text{Erreur} = \\left\\| \\mathbf{p}' - H \\mathbf{p} \\right\\|\n",
    "   ] $$\n",
    "   où \\( \\mathbf{p} \\) est un point dans l'image source et \\( \\mathbf{p}' \\) est son point correspondant dans l'image cible.\n",
    "\n",
    "2. **Score RANSAC (Random Sample Consensus)** :  \n",
    "   RANSAC est une méthode robuste utilisée pour estimer des modèles tout en rejetant les correspondances incorrectes (outliers). Dans le contexte de l’homographie, RANSAC permet de calculer l’homographie tout en écartant les points qui ne correspondent pas bien à la transformation projetée. Le score RANSAC est un bon indice de confiance : un score élevé indique que la majorité des points de correspondance sont corrects, tandis qu’un score faible suggère que l’homographie n'est pas fiable.\n",
    "\n",
    "3. **Inliers et outliers** :  \n",
    "   Les points **inliers** sont ceux qui respectent bien l’homographie estimée, tandis que les **outliers** sont des points qui ne correspondent pas à la transformation. Une grande proportion d’inliers par rapport aux outliers signifie que l’homographie est robuste et fiable. Si la proportion d'inliers est faible, cela indique une estimation erronée.\n",
    "\n",
    "4. **Matrice de covariance des paramètres de l’homographie** :  \n",
    "   Une autre méthode pour évaluer la fiabilité de l’homographie consiste à analyser la **matrice de covariance** des paramètres estimés. Cette matrice donne une mesure de l'incertitude associée aux coefficients de l’homographie. Si la covariance est faible, cela signifie que les paramètres sont estimés avec une bonne précision. Si elle est élevée, cela indique une incertitude élevée dans l’estimation des paramètres de l’homographie.\n",
    "\n",
    "5. **Validation visuelle** :  \n",
    "   Une méthode simple mais efficace est de visualiser l’homographie estimée sur un échantillon de points. Si l’homographie transforme les points d'une image de manière cohérente avec ceux de l’autre image, l'estimation est probablement fiable. L'utilisation de logiciels comme OpenCV permet de vérifier visuellement l'exactitude de l'homographie estimée.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q4 : Modifier le script fourni afin de saisir les points par paires entre deux images, de façon à réaliser un panorama comme dans l'exemple de la Figure 2.\n",
    "\n",
    "Voici le code pour créer un panorama :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "qt.qpa.plugin: Could not find the Qt platform plugin \"wayland\" in \"/home/youssef/Desktop/Labs_Computer_Vision/new-venv/lib/python3.12/site-packages/cv2/qt/plugins\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cliquez pour sélectionner des points correspondants dans les deux images.\n",
      "Cliquez sur 'q' pour passer à l'image suivante et terminer la sélection.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "# Fonction pour sélectionner des points dans deux images\n",
    "def select_points(event, x, y, flags, param):\n",
    "    global points_selected, img1_points, img2_points, img1, img2, img1_clone, img2_clone, current_image\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        points_selected += 1\n",
    "        if current_image == 1:\n",
    "            cv2.circle(img1, (x, y), 5, (0, 255, 0), -1)\n",
    "            img1_points.append([x, y])\n",
    "        elif current_image == 2:\n",
    "            cv2.circle(img2, (x, y), 5, (255, 0, 0), -1)\n",
    "            img2_points.append([x, y])\n",
    "    elif event == cv2.EVENT_RBUTTONDOWN:  # Réinitialiser\n",
    "        points_selected = 0\n",
    "        img1_points = []\n",
    "        img2_points = []\n",
    "        img1 = img1_clone.copy()\n",
    "        img2 = img2_clone.copy()\n",
    "\n",
    "# Charger les images\n",
    "img1_path = \"./Images_Homographie/keble_a.jpg\"\n",
    "img2_path = \"./Images_Homographie/keble_b.jpg\"\n",
    "\n",
    "if not os.path.exists(img1_path) or not os.path.exists(img2_path):\n",
    "    print(\"Erreur : Une ou les deux images sont introuvables.\")\n",
    "    exit(1)\n",
    "\n",
    "img1 = cv2.imread(img1_path)\n",
    "img2 = cv2.imread(img2_path)\n",
    "\n",
    "if img1 is None or img2 is None:\n",
    "    print(\"Erreur : Impossible de charger une ou les deux images.\")\n",
    "    exit(1)\n",
    "\n",
    "# Cloner les images pour les réinitialisations\n",
    "img1_clone = img1.copy()\n",
    "img2_clone = img2.copy()\n",
    "\n",
    "# Variables pour stocker les points\n",
    "points_selected = 0\n",
    "img1_points = []\n",
    "img2_points = []\n",
    "current_image = 1\n",
    "\n",
    "# Configuration de la fenêtre pour sélectionner les points\n",
    "cv2.namedWindow(\"Image 1\")\n",
    "cv2.namedWindow(\"Image 2\")\n",
    "cv2.setMouseCallback(\"Image 1\", select_points)\n",
    "cv2.setMouseCallback(\"Image 2\", select_points)\n",
    "\n",
    "print(\"Cliquez pour sélectionner des points correspondants dans les deux images.\")\n",
    "print(\"Cliquez sur 'q' pour passer à l'image suivante et terminer la sélection.\")\n",
    "\n",
    "# Sélectionner les points dans les deux images\n",
    "while True:\n",
    "    cv2.imshow(\"Image 1\", img1)\n",
    "    cv2.imshow(\"Image 2\", img2)\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord(\"q\") and points_selected >= 4:\n",
    "        if current_image == 1:\n",
    "            current_image = 2\n",
    "        else:\n",
    "            break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Vérification des points sélectionnés\n",
    "if len(img1_points) < 4 or len(img2_points) < 4:\n",
    "    print(\"Erreur : Vous devez sélectionner au moins 4 points dans chaque image.\")\n",
    "    exit(1)\n",
    "\n",
    "# Conversion en numpy arrays\n",
    "img1_points = np.array(img1_points, dtype=np.float32)\n",
    "img2_points = np.array(img2_points, dtype=np.float32)\n",
    "\n",
    "# Calculer l'homographie entre les deux images\n",
    "H, status = cv2.findHomography(img2_points, img1_points, method=cv2.RANSAC)\n",
    "print(f\"Matrice H estimée :\\n{H}\")\n",
    "\n",
    "# Appliquer l'homographie pour transformer la deuxième image\n",
    "height, width, _ = img1.shape\n",
    "img2_transformed = cv2.warpPerspective(img2, H, (width * 2, height))\n",
    "\n",
    "# Fusionner les deux images pour créer le panorama\n",
    "panorama = img2_transformed.copy()\n",
    "panorama[0:img1.shape[0], 0:img1.shape[1]] = img1\n",
    "\n",
    "# Afficher et sauvegarder le panorama\n",
    "cv2.imshow(\"Panorama\", panorama)\n",
    "key = cv2.waitKey(0)\n",
    "if key == ord(\"s\"):\n",
    "    cv2.imwrite(\"panorama.png\", panorama)\n",
    "    print(\"Panorama sauvegardé sous 'panorama.png'\")\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conditions pour la prise de vue\n",
    "\n",
    "Pour que cette méthode fonctionne bien, la prise de vue entre les deux images doit respecter les conditions suivantes :\n",
    "\n",
    "- **Les images doivent partager un champ de vision similaire.** Cela signifie que les images doivent être prises avec une certaine superposition entre elles. Une bonne règle de base est de s'assurer que chaque image couvre environ 30 à 50% de la zone de l'image précédente.\n",
    "  \n",
    "- **Les perspectives doivent être raisonnablement proches.** Les images ne doivent pas être prises avec des rotations extrêmes ou des angles de vue trop différents. Sinon, l’homographie peut ne pas être estimée correctement.\n",
    "\n",
    "- **Il doit y avoir suffisamment de points correspondants.** Plus vous avez de points correspondants bien répartis entre les deux images, plus l'estimation de l'homographie sera précise et robuste.\n",
    "\n",
    "### Retrouver les paramètres de la transformation à partir de l’homographie\n",
    "\n",
    "Les paramètres de la transformation projetée entre les deux images sont contenus dans la matrice d’homographie \\( H \\) estimée. Cette matrice est une transformation projective qui peut être utilisée pour calculer la transformation d’un plan sur un autre. La matrice \\( H \\) contient les coefficients qui définissent la relation entre les coordonnées des points dans l'image source et ceux dans l'image cible :\n",
    "\n",
    "$$ [\n",
    "H = \\begin{pmatrix} \n",
    "h_{11} & h_{12} & h_{13} \\\\\n",
    "h_{21} & h_{22} & h_{23} \\\\\n",
    "h_{31} & h_{32} & h_{33}\n",
    "\\end{pmatrix}\n",
    "]$$\n",
    "\n",
    "- Les coefficients  \\( h_{11}, h_{12}, h_{21}, h_{22}, h_{13}, h_{23} \\) définissent les transformations affines et projectives.\n",
    "- \\( h_{31}, h_{32} \\) affectent la perspective et la déformation.\n",
    "- \\( h_{33} \\) est souvent normalisé à 1 pour simplifier les calculs.\n",
    "\n",
    "Cette matrice permet de transformer un point \\( (x, y) \\) de l’image source en un point \\( (x', y') \\) de l’image cible à l'aide de la relation suivante :\n",
    "\\[\n",
    "\\begin{bmatrix} x' \\\\ y' \\\\ 1 \\end{bmatrix} = H \\cdot \\begin{bmatrix} x \\\\ y \\\\ 1 \\end{bmatrix}\n",
    "\\]\n",
    "\n",
    "La matrice \\( H \\) permet donc de retrouver les transformations géométriques entre les deux images (translation, rotation, et déformation de perspective)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
